{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numOfClass     :  2\n",
      "numOfFeatures  :  2\n",
      "datasetLength  :  200  \n",
      "\n",
      "4 [16.29801286, 24.07634407, 1] 2\n",
      "5 [15.27514278, 23.13210272, 1] 2\n",
      "6 [7.89445047, 12.59292776, 2] 1\n",
      "7 [8.09764253, 12.12033653, 2] 1\n",
      "\n",
      "Accuracy : 98.0 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import exp, sqrt\n",
    "\n",
    "\n",
    "#TrainData = open(\"Train.txt\") \n",
    "#TestData = open(\"Test.txt\")\n",
    "TrainData = open(\"train1.txt\") # during evaluation\n",
    "TestData = open(\"test1.txt\")\n",
    "\n",
    "numOfClass, numOfFeatures, datasetLength = 0,0,0\n",
    "dataset = []\n",
    "\n",
    "\n",
    "rows = TrainData.readlines()\n",
    "count = 0\n",
    "\n",
    "for r in rows:\n",
    "    if(count == 0):\n",
    "        var = r.split()\n",
    "        numOfFeatures = int(var[0])\n",
    "        numOfClass = int(var[1])\n",
    "        datasetLength = int(var[2])\n",
    "    else:\n",
    "        var = r.split()\n",
    "        size = len(var)\n",
    "        data = []\n",
    "        index = 0\n",
    "        for i in var:\n",
    "            if(index == size - 1):\n",
    "                data.append(int(i))\n",
    "            else:\n",
    "                data.append(float(i))\n",
    "            index = index + 1\n",
    "        dataset.append(data)\n",
    "    count = count + 1\n",
    "\n",
    "print('numOfClass     : ',numOfClass)\n",
    "print('numOfFeatures  : ', numOfFeatures)\n",
    "print('datasetLength  : ', datasetLength , ' \\n')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class_wise_dataset = []\n",
    "\n",
    "classes = set()\n",
    "\n",
    "for data in dataset:\n",
    "    classes.add(data[numOfFeatures])\n",
    "\n",
    "prior_probability = []\n",
    "\n",
    "for c in classes:\n",
    "    d = []\n",
    "    cnt = 0\n",
    "    for data in dataset:\n",
    "        if data[numOfFeatures] == c:\n",
    "            d.append(data)\n",
    "            cnt = cnt + 1\n",
    "    class_wise_dataset.append(d)\n",
    "    prior_probability.append(float(cnt/datasetLength))\n",
    "    \n",
    "\n",
    "\n",
    "class_wise_avg = []\n",
    "class_wise_std_dev = []\n",
    "class_wise_co_var = []\n",
    "test_dataset = []\n",
    "\n",
    "for c in classes:\n",
    "    avg = []\n",
    "    for i in range(numOfFeatures):\n",
    "        sum = 0\n",
    "        for data in class_wise_dataset[c-1]:\n",
    "            sum = sum + data[i]\n",
    "        average = sum/len(class_wise_dataset[c-1])\n",
    "        avg.append(average)\n",
    "    class_wise_avg.append(avg)\n",
    "    \n",
    "\n",
    "for i in range(numOfFeatures):\n",
    "    row = []\n",
    "    for j in range(numOfFeatures):\n",
    "        sum = 0\n",
    "        for data in dataset:\n",
    "            sum = sum + (data[i] - avg[i]) * (data[j] - avg[j])\n",
    "        row.append(float(sum/datasetLength))\n",
    "    class_wise_co_var.append(row)\n",
    "\n",
    "\n",
    "co_variance_matrix = np.matrix(class_wise_co_var)\n",
    "\n",
    "inv_co_variance_matrix = np.linalg.inv(co_variance_matrix)\n",
    "\n",
    "det = np.linalg.det(co_variance_matrix)\n",
    "\n",
    "lines = TestData.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    var = line.split()\n",
    "    size = len(var)\n",
    "    data = []\n",
    "    idx = 0\n",
    "    for i in var:\n",
    "        if(idx == size - 1):\n",
    "            data.append(int(i))\n",
    "        else:\n",
    "            data.append(float(i))\n",
    "        idx = idx + 1\n",
    "    test_dataset.append(data)\n",
    "    \n",
    "\n",
    "\n",
    "feature_vectors = []\n",
    "\n",
    "for data in test_dataset:\n",
    "    s = data.pop()\n",
    "    feature_vector = np.matrix(data)\n",
    "    feature_vector = np.transpose(feature_vector)\n",
    "    feature_vectors.append(feature_vector)\n",
    "    data.append(s)\n",
    "\n",
    "\n",
    "def multivariate(num,dt,x,y):\n",
    "    cc = float(1/((2*3.1416)**float(num/2))*sqrt(dt))\n",
    "    m = cc*exp(-0.5*x.transpose()*(y*x))\n",
    "    return m\n",
    "\n",
    "    \n",
    "output = []\n",
    "\n",
    "\n",
    "for test_data in feature_vectors:\n",
    "    posterior = []\n",
    "    for c in range(numOfClass):\n",
    "        x = np.matrix(test_data - np.matrix(class_wise_avg[c]).transpose())\n",
    "        mul = multivariate(numOfFeatures,det,x,inv_co_variance_matrix)\n",
    "        mul = mul*prior_probability[c]\n",
    "        posterior.append(mul)\n",
    "    output.append(posterior)\n",
    "\n",
    "\n",
    "accuracy = 0\n",
    "count = 0\n",
    "\n",
    "for out in output:\n",
    "    if test_dataset[count][numOfFeatures] == out.index(max(out))+1:\n",
    "        accuracy = accuracy + 1\n",
    "    else:\n",
    "        print(1+count , test_dataset[count], out.index(max(out))+1)\n",
    "    count = count + 1 \n",
    "\n",
    "print(\"\\nAccuracy :\" , float((accuracy/len(test_dataset)))*100 , '%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
